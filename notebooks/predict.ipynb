{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.optim as optim\n",
    "from process import NBADataProcessor, NBADataset\n",
    "from model import SimpleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the prediction dataset\n",
    "predict_path = 'datasets/predict.csv'\n",
    "predict_file = os.path.join(os.getcwd(), predict_path)\n",
    "\n",
    "# Load the prediction data\n",
    "predict_df = pd.read_csv(predict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.025     , 0.52954545, 0.38676471, ..., 0.49326923, 0.6       ,\n",
       "        1.        ],\n",
       "       [0.025     , 0.52954545, 0.38676471, ..., 0.49326923, 0.6       ,\n",
       "        0.        ],\n",
       "       [0.025     , 0.52954545, 0.38676471, ..., 0.49326923, 0.6       ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.025     , 0.52954545, 0.38676471, ..., 0.53461538, 0.6       ,\n",
       "        0.        ],\n",
       "       [0.025     , 0.52954545, 0.38676471, ..., 0.49326923, 0.6       ,\n",
       "        1.        ],\n",
       "       [0.025     , 0.52954545, 0.38676471, ..., 0.49326923, 0.6       ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features from the prediction dataset\n",
    "removed_columns = list(predict_df.columns[predict_df.dtypes == \"object\"])\n",
    "selected_columns = predict_df.columns[~predict_df.columns.isin(removed_columns)]\n",
    "\n",
    "# Exclude columns with specific words\n",
    "excluded_words = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "features_columns = [col for col in selected_columns if not any(word in col for word in excluded_words)]\n",
    "\n",
    "predict_features = predict_df[features_columns].values\n",
    "predict_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the prediction data\n",
    "predict_dataset = NBADataset(predict_features, target=None)  # Set target to None\n",
    "predict_dataloader = DataLoader(predict_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = len(features_columns)\n",
    "net = SimpleNet(input_size=input_size)\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "model_name = 'model_state_dict.pth'\n",
    "net.load_state_dict(torch.load(model_name), strict=False)\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/andersoncompalas/Documents/SCAI_comp/predict.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andersoncompalas/Documents/SCAI_comp/predict.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andersoncompalas/Documents/SCAI_comp/predict.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andersoncompalas/Documents/SCAI_comp/predict.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m inputs,labels \u001b[39min\u001b[39;49;00m predict_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andersoncompalas/Documents/SCAI_comp/predict.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39;49m inputs\u001b[39m.\u001b[39;49mto(device), labels\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andersoncompalas/Documents/SCAI_comp/predict.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         outputs \u001b[39m=\u001b[39;49m net(inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 620\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/sampler.py:282\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m batch \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    281\u001b[0m idx_in_batch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 282\u001b[0m \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler:\n\u001b[1;32m    283\u001b[0m     batch[idx_in_batch] \u001b[39m=\u001b[39;49m idx\n\u001b[1;32m    284\u001b[0m     idx_in_batch \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/sampler.py:110\u001b[0m, in \u001b[0;36mSequentialSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mint\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source)))\n",
      "File \u001b[0;32m~/Documents/SCAI_comp/process.py:156\u001b[0m, in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         train_dataloader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m         \u001b[39mreturn\u001b[39;00m train_dataloader, features_columns, features_df\n\u001b[0;32m--> 156\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mNBADataset\u001b[39;00m(Dataset):\n\u001b[1;32m    157\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, features, target \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    158\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m features\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Collect predictions and probabilities\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in predict_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        predictions = torch.round(outputs)\n",
    "\n",
    "        predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Add the predictions and probabilities to the original prediction dataframe\n",
    "predict_df['predicted_probability'] = predictions\n",
    "predict_df['predicted_result'] = ['Win' if pred > 0.5 else 'Loss' for pred in predictions]\n",
    "\n",
    "# Display the DataFrame with predicted results\n",
    "result_df = predict_df[['date', 'team', 'team_opp', 'predicted_result', 'predicted_probability']]\n",
    "\n",
    "# Print team matchups and predicted results with probabilities\n",
    "for index, row in result_df.iterrows():\n",
    "    print(f\"{row['team']} vs {row['team_opp']}: {row['predicted_result']} with {row['predicted_probability'] * 100:.2f}% probability\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
