{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBADataProcessor:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        df = pd.read_csv(self.file_path, index_col=0)\n",
    "        return df\n",
    "\n",
    "    def _add_target(self, group):\n",
    "        group = pd.concat([group, group[\"won\"].shift(-1).rename(\"target\")], axis=1)\n",
    "        return group\n",
    "\n",
    "    def _scale_data(self, df, selected_columns):\n",
    "        scaler = MinMaxScaler()\n",
    "        df[selected_columns] = scaler.fit_transform(df[selected_columns])\n",
    "        return df\n",
    "\n",
    "    def _calculate_rolling_averages(self, df, selected_columns):\n",
    "        rolling = df[list(selected_columns) + [\"won\", \"team\", \"season\"]]\n",
    "        \n",
    "        def find_team_averages(team):\n",
    "            team[selected_columns] = team[selected_columns].rolling(10).mean()\n",
    "            return team\n",
    "\n",
    "        rolling = rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)\n",
    "\n",
    "        return rolling\n",
    "\n",
    "    def _add_future_game_data(self, df):\n",
    "        def shift_col(team, col_name):\n",
    "            next_col = team[col_name].shift(-1)\n",
    "            return next_col\n",
    "\n",
    "        df[\"home_next\"] = self._add_col(df, \"home\")\n",
    "        df[\"team_opp_next\"] = self._add_col(df, \"team_opp\")\n",
    "        df[\"date_next\"] = self._add_col(df, \"date\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _add_col(self, df, col_name):\n",
    "        return df.groupby(\"team\", group_keys=False).apply(lambda x: self._shift_col(x, col_name))\n",
    "\n",
    "    def _shift_col(self, team, col_name):\n",
    "        next_col = team[col_name].shift(-1)\n",
    "        return next_col\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        # Sort by date and drop irrelevant columns\n",
    "        self.df = self.df.sort_values(\"date\")\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        del self.df[\"mp.1\"]\n",
    "        del self.df[\"mp_opp.1\"]\n",
    "        del self.df[\"index_opp\"]\n",
    "\n",
    "        #Add a target column (Whether or not team won next game)\n",
    "        self.df = self.df.groupby(\"team\", group_keys=False).apply(self._add_target)\n",
    "        self.df.loc[pd.isnull(self.df[\"target\"]), \"target\"] = 2\n",
    "        self.df[\"target\"] = self.df[\"target\"].astype(int, errors=\"ignore\")\n",
    "        \n",
    "        #Create copy dataframe without null values\n",
    "        nulls = pd.isnull(self.df).sum()\n",
    "        nulls = nulls[nulls > 0]\n",
    "        valid_columns = self.df.columns[~self.df.columns.isin(nulls.index)]\n",
    "        self.df = self.df[valid_columns].copy()\n",
    "        \n",
    "        #Convert boolean column to binary\n",
    "        self.df['won'] = self.df['won'].astype(int)\n",
    "        \n",
    "        #Scale stat columns\n",
    "        removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "        selected_columns = self.df.columns[~self.df.columns.isin(removed_columns)]\n",
    "        self.df = self._scale_data(self.df, selected_columns)\n",
    "        rolling = self._calculate_rolling_averages(self.df, selected_columns)\n",
    "        \n",
    "        rolling_cols = [f\"{col}_10\" for col in rolling.columns]\n",
    "        rolling.columns = rolling_cols\n",
    "        \n",
    "        #Concatenate new columns back into dataframe, dropping null and resetting index\n",
    "        self.df = pd.concat([self.df, rolling], axis=1)\n",
    "        self.df = self.df.dropna()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "\n",
    "        #Add future game data to columns\n",
    "        self.df = self._add_future_game_data(self.df)\n",
    "        \n",
    "        self.df = self.df.merge(self.df[rolling_cols + [\"team_opp_next\", \"date_next\", \"team\"]], left_on=[\"team\", \"date_next\"], right_on=[\"team_opp_next\", \"date_next\"])\n",
    "\n",
    "        return self.df\n",
    "    \n",
    "    def _extract_features(self, df):\n",
    "        \n",
    "        # Extract features for team_x and team_opp_next_x\n",
    "        team_x_cols = [col for col in df.columns if '_10_x' in col and 'opp' not in col]\n",
    "        team_opp_next_x_cols = [col for col in df.columns if 'opp_10_x' in col]\n",
    "\n",
    "        # Concatenate features and rolling averages, including home_next\n",
    "        features_columns = team_x_cols + team_opp_next_x_cols + [\"home_next\"]\n",
    "        \n",
    "        # Exclude columns with specific words\n",
    "        excluded_words = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "        features_columns = [col for col in features_columns if not any(word in col for word in excluded_words)]\n",
    "        \n",
    "        features_df = df[features_columns].copy()\n",
    "\n",
    "        return features_df\n",
    "    \n",
    "class NBADataset(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.target[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Adjust dropout rate as needed\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the dataset\n",
    "relative_path = 'datasets/nba_games.csv'\n",
    "read_file = os.path.join(os.getcwd(), relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NBADataProcessor and prepare the dataset\n",
    "data_processor = NBADataProcessor(file_path=read_file)\n",
    "processed_df = data_processor.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df = processed_df[[\"season\"]].copy()\n",
    "\n",
    "# Extract features and target using the _extract_features method\n",
    "features_df = data_processor._extract_features(processed_df)\n",
    "\n",
    "# Concatenate season and date columns back to features dataframe\n",
    "features_df = pd.concat([season_df, features_df], axis=1)\n",
    "\n",
    "# Define features and target\n",
    "features_columns = features_df.columns.tolist()\n",
    "target_column = \"target\"\n",
    "\n",
    "# Identify the cutoff season (e.g., 2022)\n",
    "cutoff_season = 2022\n",
    "\n",
    "# Divide the data into training and testing sets\n",
    "train_df = features_df[features_df[\"season\"] < cutoff_season]\n",
    "test_df = features_df[features_df[\"season\"] == cutoff_season]\n",
    "\n",
    "# Extract features and target for training and testing sets\n",
    "train_features = train_df[features_columns].values\n",
    "train_target = train_df[target_column].values\n",
    "\n",
    "test_features = test_df[features_columns].values\n",
    "test_target = test_df[target_column].values\n",
    "\n",
    "# features = features_df.values\n",
    "# target = processed_df[target_column].values\n",
    "\n",
    "# # Define dataset and dataloader\n",
    "# dataset = NBADataset(features, target)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "input_size = len(features_columns)\n",
    "net = Net(input_size=input_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.6622, Accuracy: 0.6022\n",
      "Epoch 2/30, Loss: 0.6628, Accuracy: 0.6032\n",
      "Epoch 3/30, Loss: 0.6620, Accuracy: 0.6035\n",
      "Epoch 4/30, Loss: 0.6629, Accuracy: 0.6028\n",
      "Epoch 5/30, Loss: 0.6630, Accuracy: 0.6024\n",
      "Epoch 6/30, Loss: 0.6635, Accuracy: 0.6047\n",
      "Epoch 7/30, Loss: 0.6630, Accuracy: 0.6015\n",
      "Epoch 8/30, Loss: 0.6646, Accuracy: 0.6039\n",
      "Epoch 9/30, Loss: 0.6629, Accuracy: 0.5977\n",
      "Epoch 10/30, Loss: 0.6638, Accuracy: 0.6042\n",
      "Epoch 11/30, Loss: 0.6626, Accuracy: 0.6004\n",
      "Epoch 12/30, Loss: 0.6635, Accuracy: 0.6064\n",
      "Epoch 13/30, Loss: 0.6616, Accuracy: 0.6060\n",
      "Epoch 14/30, Loss: 0.6638, Accuracy: 0.6021\n",
      "Epoch 15/30, Loss: 0.6609, Accuracy: 0.6056\n",
      "Epoch 16/30, Loss: 0.6635, Accuracy: 0.6041\n",
      "Epoch 17/30, Loss: 0.6626, Accuracy: 0.6043\n",
      "Epoch 18/30, Loss: 0.6614, Accuracy: 0.6053\n",
      "Epoch 19/30, Loss: 0.6639, Accuracy: 0.6021\n",
      "Epoch 20/30, Loss: 0.6638, Accuracy: 0.6024\n",
      "Epoch 21/30, Loss: 0.6629, Accuracy: 0.6030\n",
      "Epoch 22/30, Loss: 0.6624, Accuracy: 0.6069\n",
      "Epoch 23/30, Loss: 0.6624, Accuracy: 0.6041\n",
      "Epoch 24/30, Loss: 0.6634, Accuracy: 0.6000\n",
      "Epoch 25/30, Loss: 0.6626, Accuracy: 0.6013\n",
      "Epoch 26/30, Loss: 0.6633, Accuracy: 0.6018\n",
      "Epoch 27/30, Loss: 0.6621, Accuracy: 0.6055\n",
      "Epoch 28/30, Loss: 0.6609, Accuracy: 0.6051\n",
      "Epoch 29/30, Loss: 0.6620, Accuracy: 0.6042\n",
      "Epoch 30/30, Loss: 0.6624, Accuracy: 0.6064\n",
      "Overall Accuracy: 0.6064\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for the epoch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted = torch.round(outputs)\n",
    "        correct_predictions += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate overall accuracy for the epoch\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Print the loss and accuracy for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader):.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# After the training loop, print overall accuracy\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(net.state_dict(), \"trained_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
